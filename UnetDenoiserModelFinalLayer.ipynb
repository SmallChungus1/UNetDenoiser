{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ed55f8-b325-4e15-958f-a5e173995d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6544ab05-2a1a-46df-9ab0-3e2c8ba96a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDenoise(nn.Module):\n",
    "    #layers definition\n",
    "    def __init__(self): #constructor for uNetDenoise\n",
    "        super().__init__() #constructor of parent class to init inherited attributes\n",
    "        #Encoder portion, with 256x256x3 input. Padding: same for 3x3 convolutions\n",
    "\n",
    "        #1st downsample layer\n",
    "        self.conv11 = nn.Conv2d(1,64,kernel_size=3, padding=1) #dataset images are black and white\n",
    "        self.conv12 = nn.Conv2d(64,64, kernel_size=3, padding=1) #keep padding same, (kernselSize-1)/2\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #2nd downsample layer\n",
    "        self.conv21 = nn.Conv2d(64,128,kernel_size=3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(128,128,kernel_size=3, padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #3rd downsample layer\n",
    "        self.conv31 = nn.Conv2d(128,256,kernel_size=3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(256,256,kernel_size=3, padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #4th downsample layer\n",
    "        self.conv41 = nn.Conv2d(256,512,kernel_size=3, padding=1)\n",
    "        self.conv42 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
    "        self.pool4=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #bottle neck\n",
    "        self.conv51 = nn.Conv2d(512,1024,kernel_size=3, padding=1)\n",
    "        self.conv52 = nn.Conv2d(1024,1024,kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024,512,kernel_size=2,stride=2) #1024, but half \n",
    "        self.u11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(512,256,kernel_size=2,stride=2)\n",
    "        self.u21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.u22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(256,128,kernel_size=2,stride=2)\n",
    "        self.u31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.u32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 4\n",
    "        self.upconv4 = nn.ConvTranspose2d(128,64,kernel_size=2,stride=2)\n",
    "        self.u41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.u42 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #encoder forward\n",
    "        xconv11 = relu(self.conv11(x))\n",
    "        xconv12 = relu(self.conv12(xconv11))\n",
    "        xpool1 = self.pool1(xconv12)\n",
    "\n",
    "        xconv21 = relu(self.conv21(xpool1))\n",
    "        xconv22 = relu(self.conv22(xconv21))\n",
    "        xpool2 = self.pool2(xconv22)\n",
    "\n",
    "        xconv31 = relu(self.conv31(xpool2))\n",
    "        xconv32 = relu(self.conv32(xconv31))\n",
    "        xpool3 = self.pool3(xconv32)\n",
    "\n",
    "        xconv41 = relu(self.conv41(xpool3))\n",
    "        xconv42 = relu(self.conv42(xconv41))\n",
    "        xpool4 = self.pool4(xconv42)\n",
    "\n",
    "        xconv51 = relu(self.conv51(xpool4))\n",
    "        xconv52 = relu(self.conv52(xconv51))\n",
    "\n",
    "        #decoder forward \n",
    "        xup1 = self.upconv1(xconv52)\n",
    "        xu11 = torch.cat([xup1, xconv42], dim=1)\n",
    "        xd11 = relu(self.u11(xu11))\n",
    "        xd12 = relu(self.u12(xd11))\n",
    "\n",
    "        xup2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xup2, xconv32], dim=1)\n",
    "        xd21 = relu(self.u21(xu22))\n",
    "        xd22 = relu(self.u22(xd21))\n",
    "\n",
    "        xup3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xup3, xconv22], dim=1)\n",
    "        xd31 = relu(self.u31(xu33))\n",
    "        xd32 = relu(self.u32(xd31))\n",
    "\n",
    "        xup4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xup4, xconv12], dim=1)\n",
    "        xd41 = relu(self.u41(xu44))\n",
    "        xd42 = relu(self.u42(xd41))\n",
    "\n",
    "        return xd42\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b914c7-cd0a-4f92-9865-5576ad5202f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 256, 256]        640\n",
      "├─Conv2d: 1-2                            [-1, 64, 256, 256]        36,928\n",
      "├─MaxPool2d: 1-3                         [-1, 64, 128, 128]        --\n",
      "├─Conv2d: 1-4                            [-1, 128, 128, 128]       73,856\n",
      "├─Conv2d: 1-5                            [-1, 128, 128, 128]       147,584\n",
      "├─MaxPool2d: 1-6                         [-1, 128, 64, 64]         --\n",
      "├─Conv2d: 1-7                            [-1, 256, 64, 64]         295,168\n",
      "├─Conv2d: 1-8                            [-1, 256, 64, 64]         590,080\n",
      "├─MaxPool2d: 1-9                         [-1, 256, 32, 32]         --\n",
      "├─Conv2d: 1-10                           [-1, 512, 32, 32]         1,180,160\n",
      "├─Conv2d: 1-11                           [-1, 512, 32, 32]         2,359,808\n",
      "├─MaxPool2d: 1-12                        [-1, 512, 16, 16]         --\n",
      "├─Conv2d: 1-13                           [-1, 1024, 16, 16]        4,719,616\n",
      "├─Conv2d: 1-14                           [-1, 1024, 16, 16]        9,438,208\n",
      "├─ConvTranspose2d: 1-15                  [-1, 512, 32, 32]         2,097,664\n",
      "├─Conv2d: 1-16                           [-1, 512, 32, 32]         4,719,104\n",
      "├─Conv2d: 1-17                           [-1, 512, 32, 32]         2,359,808\n",
      "├─ConvTranspose2d: 1-18                  [-1, 256, 64, 64]         524,544\n",
      "├─Conv2d: 1-19                           [-1, 256, 64, 64]         1,179,904\n",
      "├─Conv2d: 1-20                           [-1, 256, 64, 64]         590,080\n",
      "├─ConvTranspose2d: 1-21                  [-1, 128, 128, 128]       131,200\n",
      "├─Conv2d: 1-22                           [-1, 128, 128, 128]       295,040\n",
      "├─Conv2d: 1-23                           [-1, 128, 128, 128]       147,584\n",
      "├─ConvTranspose2d: 1-24                  [-1, 64, 256, 256]        32,832\n",
      "├─Conv2d: 1-25                           [-1, 64, 256, 256]        73,792\n",
      "├─Conv2d: 1-26                           [-1, 1, 256, 256]         577\n",
      "==========================================================================================\n",
      "Total params: 30,994,177\n",
      "Trainable params: 30,994,177\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 52.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 272.50\n",
      "Params size (MB): 118.23\n",
      "Estimated Total Size (MB): 390.98\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 256, 256]        640\n",
       "├─Conv2d: 1-2                            [-1, 64, 256, 256]        36,928\n",
       "├─MaxPool2d: 1-3                         [-1, 64, 128, 128]        --\n",
       "├─Conv2d: 1-4                            [-1, 128, 128, 128]       73,856\n",
       "├─Conv2d: 1-5                            [-1, 128, 128, 128]       147,584\n",
       "├─MaxPool2d: 1-6                         [-1, 128, 64, 64]         --\n",
       "├─Conv2d: 1-7                            [-1, 256, 64, 64]         295,168\n",
       "├─Conv2d: 1-8                            [-1, 256, 64, 64]         590,080\n",
       "├─MaxPool2d: 1-9                         [-1, 256, 32, 32]         --\n",
       "├─Conv2d: 1-10                           [-1, 512, 32, 32]         1,180,160\n",
       "├─Conv2d: 1-11                           [-1, 512, 32, 32]         2,359,808\n",
       "├─MaxPool2d: 1-12                        [-1, 512, 16, 16]         --\n",
       "├─Conv2d: 1-13                           [-1, 1024, 16, 16]        4,719,616\n",
       "├─Conv2d: 1-14                           [-1, 1024, 16, 16]        9,438,208\n",
       "├─ConvTranspose2d: 1-15                  [-1, 512, 32, 32]         2,097,664\n",
       "├─Conv2d: 1-16                           [-1, 512, 32, 32]         4,719,104\n",
       "├─Conv2d: 1-17                           [-1, 512, 32, 32]         2,359,808\n",
       "├─ConvTranspose2d: 1-18                  [-1, 256, 64, 64]         524,544\n",
       "├─Conv2d: 1-19                           [-1, 256, 64, 64]         1,179,904\n",
       "├─Conv2d: 1-20                           [-1, 256, 64, 64]         590,080\n",
       "├─ConvTranspose2d: 1-21                  [-1, 128, 128, 128]       131,200\n",
       "├─Conv2d: 1-22                           [-1, 128, 128, 128]       295,040\n",
       "├─Conv2d: 1-23                           [-1, 128, 128, 128]       147,584\n",
       "├─ConvTranspose2d: 1-24                  [-1, 64, 256, 256]        32,832\n",
       "├─Conv2d: 1-25                           [-1, 64, 256, 256]        73,792\n",
       "├─Conv2d: 1-26                           [-1, 1, 256, 256]         577\n",
       "==========================================================================================\n",
       "Total params: 30,994,177\n",
       "Trainable params: 30,994,177\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 52.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.25\n",
       "Forward/backward pass size (MB): 272.50\n",
       "Params size (MB): 118.23\n",
       "Estimated Total Size (MB): 390.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = UNetDenoise()\n",
    "summary(model1, (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c2040a-d5c7-4835-83ae-efa0f5b40d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #using gpu\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eddad30-58b1-4ee9-b3c8-2d61148ed9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5ea17e-96dc-472b-bab9-1158a3c57ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform) #handles label creation, class names for imgs\n",
    "        \n",
    "    def __len__(self): #to let dataloader know len of data\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26a8215-b006-4f25-98b5-9759c5fc6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\Desktop\\projects_desktop\\UNetDenoiser\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bb380c-395a-44b0-9f9b-2a733aad267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb17862-4676-4ff2-9b2e-04b2775f14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eafc950-d7e7-45ee-84be-48a0cc49cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\Desktop\\projects_desktop\\UNetDenoiser\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214bd402-fd3c-4848-bc27-02a3ffd5f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'imgDataset/Train400/'\n",
    "test_dir = 'imgDataset/Test68/'\n",
    "train_dataset =getDataset(train_dir, preprocess)\n",
    "test_dataset =getDataset(test_dir, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec107192-a433-49ac-93cf-3271df134937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba06f500-4b53-4700-9081-8b5733e507be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b57ab0-5954-45e6-9bf8-8afd11151b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786ae842-5fb6-4f3c-a079-df2aed99a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd60be6e-4c95-42d9-a4d0-457a69431c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetDenoise(\n",
       "  (conv11): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv21): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv31): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv41): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv51): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv52): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u11): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u21): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u31): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u41): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u42): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 50\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af75c6d7-fe12-4229-902f-8deb38a10c8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(clean_images.shape)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(clean_images)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, clean_images)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyTorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyTorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m, in \u001b[0;36mUNetDenoise.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m#encoder forward\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     xconv11 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv11(x))\n\u001b[1;32m---> 54\u001b[0m     xconv12 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv12\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxconv11\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     55\u001b[0m     xpool1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(xconv12)\n\u001b[0;32m     57\u001b[0m     xconv21 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv21(xpool1))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyTorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyTorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyTorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyTorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    curBatch = 0\n",
    "    lossList = list()\n",
    "    for images, labels in train_loader:\n",
    "        curBatch += 1\n",
    "        clean_images = images.to(device)\n",
    "        #print(clean_images.shape)\n",
    "        noisy_images = torch.randn_like(clean_images).to(device)\n",
    "        outputs = model1(noisy_images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, clean_images)\n",
    "        \n",
    "        # Zero gradients, backward pass, and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossList.append(loss.item())\n",
    "        \n",
    "        print(f\" Batch: {curBatch} Of: {len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {sum(lossList)/len(lossList):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f6260-953b-4ad0-82d3-9f02b975968b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
