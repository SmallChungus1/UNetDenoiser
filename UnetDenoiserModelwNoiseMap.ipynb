{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ed55f8-b325-4e15-958f-a5e173995d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    " \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "#from skimage import measure\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6544ab05-2a1a-46df-9ab0-3e2c8ba96a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDenoise(nn.Module):\n",
    "    #layers definition\n",
    "    def __init__(self): #constructor for uNetDenoise\n",
    "        super().__init__() #constructor of parent class to init inherited attributes\n",
    "        #Encoder portion, with 256x256x3 input. Padding: same for 3x3 convolutions\n",
    "\n",
    "        #1st downsample layer\n",
    "        self.conv11 = nn.Conv2d(2,64,kernel_size=3, padding=1) #dataset images are black and white\n",
    "        self.conv12 = nn.Conv2d(64,64, kernel_size=3, padding=1) #keep padding same, (kernselSize-1)/2\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #2nd downsample layer\n",
    "        self.conv21 = nn.Conv2d(64,128,kernel_size=3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(128,128,kernel_size=3, padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #3rd downsample layer\n",
    "        self.conv31 = nn.Conv2d(128,256,kernel_size=3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(256,256,kernel_size=3, padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #4th downsample layer\n",
    "        self.conv41 = nn.Conv2d(256,512,kernel_size=3, padding=1)\n",
    "        self.conv42 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
    "        self.pool4=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #bottle neck\n",
    "        self.conv51 = nn.Conv2d(512,1024,kernel_size=3, padding=1)\n",
    "        self.conv52 = nn.Conv2d(1024,1024,kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024,512,kernel_size=2,stride=2) #1024, but half \n",
    "        self.u11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(512,256,kernel_size=2,stride=2)\n",
    "        self.u21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.u22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(256,128,kernel_size=2,stride=2)\n",
    "        self.u31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.u32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 4\n",
    "        self.upconv4 = nn.ConvTranspose2d(128,64,kernel_size=2,stride=2)\n",
    "        self.u41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.u42 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #encoder forward\n",
    "        xconv11 = relu(self.conv11(x))\n",
    "        xconv12 = relu(self.conv12(xconv11))\n",
    "        xpool1 = self.pool1(xconv12)\n",
    "\n",
    "        xconv21 = relu(self.conv21(xpool1))\n",
    "        xconv22 = relu(self.conv22(xconv21))\n",
    "        xpool2 = self.pool2(xconv22)\n",
    "\n",
    "        xconv31 = relu(self.conv31(xpool2))\n",
    "        xconv32 = relu(self.conv32(xconv31))\n",
    "        xpool3 = self.pool3(xconv32)\n",
    "\n",
    "        xconv41 = relu(self.conv41(xpool3))\n",
    "        xconv42 = relu(self.conv42(xconv41))\n",
    "        xpool4 = self.pool4(xconv42)\n",
    "\n",
    "        xconv51 = relu(self.conv51(xpool4))\n",
    "        xconv52 = relu(self.conv52(xconv51))\n",
    "\n",
    "        #decoder forward \n",
    "        xup1 = self.upconv1(xconv52)\n",
    "        xu11 = torch.cat([xup1, xconv42], dim=1)\n",
    "        xd11 = relu(self.u11(xu11))\n",
    "        xd12 = relu(self.u12(xd11))\n",
    "\n",
    "        xup2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xup2, xconv32], dim=1)\n",
    "        xd21 = relu(self.u21(xu22))\n",
    "        xd22 = relu(self.u22(xd21))\n",
    "\n",
    "        xup3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xup3, xconv22], dim=1)\n",
    "        xd31 = relu(self.u31(xu33))\n",
    "        xd32 = relu(self.u32(xd31))\n",
    "\n",
    "        xup4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xup4, xconv12], dim=1)\n",
    "        xd41 = relu(self.u41(xu44))\n",
    "        xd42 = relu(self.u42(xd41))\n",
    "\n",
    "        return xd42\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b914c7-cd0a-4f92-9865-5576ad5202f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 256, 256]        1,216\n",
      "├─Conv2d: 1-2                            [-1, 64, 256, 256]        36,928\n",
      "├─MaxPool2d: 1-3                         [-1, 64, 128, 128]        --\n",
      "├─Conv2d: 1-4                            [-1, 128, 128, 128]       73,856\n",
      "├─Conv2d: 1-5                            [-1, 128, 128, 128]       147,584\n",
      "├─MaxPool2d: 1-6                         [-1, 128, 64, 64]         --\n",
      "├─Conv2d: 1-7                            [-1, 256, 64, 64]         295,168\n",
      "├─Conv2d: 1-8                            [-1, 256, 64, 64]         590,080\n",
      "├─MaxPool2d: 1-9                         [-1, 256, 32, 32]         --\n",
      "├─Conv2d: 1-10                           [-1, 512, 32, 32]         1,180,160\n",
      "├─Conv2d: 1-11                           [-1, 512, 32, 32]         2,359,808\n",
      "├─MaxPool2d: 1-12                        [-1, 512, 16, 16]         --\n",
      "├─Conv2d: 1-13                           [-1, 1024, 16, 16]        4,719,616\n",
      "├─Conv2d: 1-14                           [-1, 1024, 16, 16]        9,438,208\n",
      "├─ConvTranspose2d: 1-15                  [-1, 512, 32, 32]         2,097,664\n",
      "├─Conv2d: 1-16                           [-1, 512, 32, 32]         4,719,104\n",
      "├─Conv2d: 1-17                           [-1, 512, 32, 32]         2,359,808\n",
      "├─ConvTranspose2d: 1-18                  [-1, 256, 64, 64]         524,544\n",
      "├─Conv2d: 1-19                           [-1, 256, 64, 64]         1,179,904\n",
      "├─Conv2d: 1-20                           [-1, 256, 64, 64]         590,080\n",
      "├─ConvTranspose2d: 1-21                  [-1, 128, 128, 128]       131,200\n",
      "├─Conv2d: 1-22                           [-1, 128, 128, 128]       295,040\n",
      "├─Conv2d: 1-23                           [-1, 128, 128, 128]       147,584\n",
      "├─ConvTranspose2d: 1-24                  [-1, 64, 256, 256]        32,832\n",
      "├─Conv2d: 1-25                           [-1, 64, 256, 256]        73,792\n",
      "├─Conv2d: 1-26                           [-1, 1, 256, 256]         577\n",
      "==========================================================================================\n",
      "Total params: 30,994,753\n",
      "Trainable params: 30,994,753\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 52.19\n",
      "==========================================================================================\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 272.50\n",
      "Params size (MB): 118.24\n",
      "Estimated Total Size (MB): 391.24\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 256, 256]        1,216\n",
       "├─Conv2d: 1-2                            [-1, 64, 256, 256]        36,928\n",
       "├─MaxPool2d: 1-3                         [-1, 64, 128, 128]        --\n",
       "├─Conv2d: 1-4                            [-1, 128, 128, 128]       73,856\n",
       "├─Conv2d: 1-5                            [-1, 128, 128, 128]       147,584\n",
       "├─MaxPool2d: 1-6                         [-1, 128, 64, 64]         --\n",
       "├─Conv2d: 1-7                            [-1, 256, 64, 64]         295,168\n",
       "├─Conv2d: 1-8                            [-1, 256, 64, 64]         590,080\n",
       "├─MaxPool2d: 1-9                         [-1, 256, 32, 32]         --\n",
       "├─Conv2d: 1-10                           [-1, 512, 32, 32]         1,180,160\n",
       "├─Conv2d: 1-11                           [-1, 512, 32, 32]         2,359,808\n",
       "├─MaxPool2d: 1-12                        [-1, 512, 16, 16]         --\n",
       "├─Conv2d: 1-13                           [-1, 1024, 16, 16]        4,719,616\n",
       "├─Conv2d: 1-14                           [-1, 1024, 16, 16]        9,438,208\n",
       "├─ConvTranspose2d: 1-15                  [-1, 512, 32, 32]         2,097,664\n",
       "├─Conv2d: 1-16                           [-1, 512, 32, 32]         4,719,104\n",
       "├─Conv2d: 1-17                           [-1, 512, 32, 32]         2,359,808\n",
       "├─ConvTranspose2d: 1-18                  [-1, 256, 64, 64]         524,544\n",
       "├─Conv2d: 1-19                           [-1, 256, 64, 64]         1,179,904\n",
       "├─Conv2d: 1-20                           [-1, 256, 64, 64]         590,080\n",
       "├─ConvTranspose2d: 1-21                  [-1, 128, 128, 128]       131,200\n",
       "├─Conv2d: 1-22                           [-1, 128, 128, 128]       295,040\n",
       "├─Conv2d: 1-23                           [-1, 128, 128, 128]       147,584\n",
       "├─ConvTranspose2d: 1-24                  [-1, 64, 256, 256]        32,832\n",
       "├─Conv2d: 1-25                           [-1, 64, 256, 256]        73,792\n",
       "├─Conv2d: 1-26                           [-1, 1, 256, 256]         577\n",
       "==========================================================================================\n",
       "Total params: 30,994,753\n",
       "Trainable params: 30,994,753\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 52.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.50\n",
       "Forward/backward pass size (MB): 272.50\n",
       "Params size (MB): 118.24\n",
       "Estimated Total Size (MB): 391.24\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = UNetDenoise()\n",
    "summary(model1, (2, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c2040a-d5c7-4835-83ae-efa0f5b40d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #using gpu\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eddad30-58b1-4ee9-b3c8-2d61148ed9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5ea17e-96dc-472b-bab9-1158a3c57ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform) #handles label creation, class names for imgs\n",
    "        \n",
    "    def __len__(self): #to let dataloader know len of data\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26a8215-b006-4f25-98b5-9759c5fc6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\Desktop\\projects_desktop\\UNetDenoiser\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bb380c-395a-44b0-9f9b-2a733aad267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb17862-4676-4ff2-9b2e-04b2775f14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda x: x/255) #normalization by div by 255\n",
    "    #transforms.Normalize(0,1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eafc950-d7e7-45ee-84be-48a0cc49cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\Desktop\\projects_desktop\\UNetDenoiser\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214bd402-fd3c-4848-bc27-02a3ffd5f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'imgDataset/Train400/'\n",
    "test_dir = 'imgDataset/Test68/'\n",
    "train_datasetPreSplit =getDataset(train_dir, preprocess)\n",
    "test_dataset =getDataset(test_dir, preprocess)\n",
    "train_dataset, val_dataset = random_split(train_datasetPreSplit, [int(0.85*len(train_datasetPreSplit)), len(train_datasetPreSplit)-int(0.85*len(train_datasetPreSplit))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec107192-a433-49ac-93cf-3271df134937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba06f500-4b53-4700-9081-8b5733e507be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN: 0.1411764770746231, Max: 0.9843137264251709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_dataset[1]\n",
    "print(f'MIN: {image.min()}, Max: {image.max()}')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b57ab0-5954-45e6-9bf8-8afd11151b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786ae842-5fb6-4f3c-a079-df2aed99a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001, weight_decay=1e-5)#adam adjustes the learning rate. weight decay for l2 reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7026b2e-849e-4b9a-802e-2db5bea7de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(mse, max):\n",
    "    return 10*np.log10((max**2)/mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd60be6e-4c95-42d9-a4d0-457a69431c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 50\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "model1.to(device)\n",
    "#sigma = 15/255 #maybe try 15\n",
    "psnrMin = float('inf') #to keep track of smallest psnr val for saving wieghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a39f5f40-f54c-403c-b154-d17db2126079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists to keep track of losses and metrics at end of an epoch\n",
    "epochTrainLossList = list()\n",
    "epochValLossList = list()\n",
    "epochssimOutputList = list()\n",
    "epochssimNoisyList = list()\n",
    "epochpsnrNoisyList= list()\n",
    "epochpsnrOutputList = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0a9cfa-f427-4321-9644-1aa5b59d7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise level map\n",
    "def genNoiseMap(image, sigmaNorm):\n",
    "    noiselvlMap = torch.full_like(image, sigmaNorm)\n",
    "    return noiselvlMap\n",
    "def combineImgandMap(imageNoised, noiselvlMap): #input image needs to be noised\n",
    "    combinedInput = torch.cat((imageNoised, noiselvlMap), dim=1)\n",
    "    return combinedInput\n",
    "def addNoiseMap(imageNoised, sigmaNorm): #image needs to be noised, sigma should be normalized?\n",
    "    noiselvlMap = genNoiseMap(imageNoised, sigmaNorm)\n",
    "    return combineImgandMap(imageNoised, noiselvlMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75c6d7-fe12-4229-902f-8deb38a10c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch: 1 Of: 11, Training Loss: 0.2137, Validation loss: 0.1529 Avg SSIM of noisy images: 0.6016 Avg SSIM of output images: 0.2607 | Avg PSNR of noisy images: 36.0905  Avg PSNR of output images: 8.8858\n",
      " Batch: 2 Of: 11, Training Loss: 0.1456, Validation loss: 0.0583 Avg SSIM of noisy images: 0.6016 Avg SSIM of output images: 0.4061 | Avg PSNR of noisy images: 36.0894  Avg PSNR of output images: 10.9133\n",
      " Batch: 3 Of: 11, Training Loss: 0.0571, Validation loss: 0.0168 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.5064 | Avg PSNR of noisy images: 36.0892  Avg PSNR of output images: 13.3052\n",
      " Batch: 4 Of: 11, Training Loss: 0.0168, Validation loss: 0.0376 Avg SSIM of noisy images: 0.6016 Avg SSIM of output images: 0.5600 | Avg PSNR of noisy images: 36.0897  Avg PSNR of output images: 13.5562\n",
      " Batch: 5 Of: 11, Training Loss: 0.0380, Validation loss: 0.0134 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.5982 | Avg PSNR of noisy images: 36.0892  Avg PSNR of output images: 14.6264\n",
      " Batch: 6 Of: 11, Training Loss: 0.0142, Validation loss: 0.0057 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.6241 | Avg PSNR of noisy images: 36.0896  Avg PSNR of output images: 15.9227\n",
      " Batch: 7 Of: 11, Training Loss: 0.0061, Validation loss: 0.0114 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.6404 | Avg PSNR of noisy images: 36.0895  Avg PSNR of output images: 16.4704\n",
      " Batch: 8 Of: 11, Training Loss: 0.0119, Validation loss: 0.0129 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.6533 | Avg PSNR of noisy images: 36.0893  Avg PSNR of output images: 16.8137\n",
      " Batch: 9 Of: 11, Training Loss: 0.0159, Validation loss: 0.0080 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.6665 | Avg PSNR of noisy images: 36.0893  Avg PSNR of output images: 17.3098\n",
      " Batch: 10 Of: 11, Training Loss: 0.0094, Validation loss: 0.0036 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.6803 | Avg PSNR of noisy images: 36.0890  Avg PSNR of output images: 18.0738\n",
      " Batch: 11 Of: 11, Training Loss: 0.0031, Validation loss: 0.0056 Avg SSIM of noisy images: 0.6015 Avg SSIM of output images: 0.6930 | Avg PSNR of noisy images: 36.0889  Avg PSNR of output images: 18.5105\n",
      "Epoch [1/15], Train Loss: 0.0483, Validation Loss: 0.0292\n",
      " Batch: 1 Of: 11, Training Loss: 0.0055, Validation loss: 0.0078 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8269 | Avg PSNR of noisy images: 34.1510  Avg PSNR of output images: 21.2636\n",
      " Batch: 2 Of: 11, Training Loss: 0.0094, Validation loss: 0.0048 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8329 | Avg PSNR of noisy images: 34.1511  Avg PSNR of output images: 22.5787\n",
      " Batch: 3 Of: 11, Training Loss: 0.0048, Validation loss: 0.0041 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8305 | Avg PSNR of noisy images: 34.1507  Avg PSNR of output images: 23.1563\n",
      " Batch: 4 Of: 11, Training Loss: 0.0042, Validation loss: 0.0044 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8281 | Avg PSNR of noisy images: 34.1509  Avg PSNR of output images: 23.2631\n",
      " Batch: 5 Of: 11, Training Loss: 0.0043, Validation loss: 0.0038 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8286 | Avg PSNR of noisy images: 34.1515  Avg PSNR of output images: 23.5478\n",
      " Batch: 6 Of: 11, Training Loss: 0.0034, Validation loss: 0.0031 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8299 | Avg PSNR of noisy images: 34.1512  Avg PSNR of output images: 23.8877\n",
      " Batch: 7 Of: 11, Training Loss: 0.0028, Validation loss: 0.0025 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8315 | Avg PSNR of noisy images: 34.1509  Avg PSNR of output images: 24.1527\n",
      " Batch: 8 Of: 11, Training Loss: 0.0026, Validation loss: 0.0038 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8326 | Avg PSNR of noisy images: 34.1512  Avg PSNR of output images: 24.3320\n",
      " Batch: 9 Of: 11, Training Loss: 0.0033, Validation loss: 0.0027 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8334 | Avg PSNR of noisy images: 34.1511  Avg PSNR of output images: 24.5150\n",
      " Batch: 10 Of: 11, Training Loss: 0.0029, Validation loss: 0.0029 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8337 | Avg PSNR of noisy images: 34.1511  Avg PSNR of output images: 24.6561\n",
      " Batch: 11 Of: 11, Training Loss: 0.0029, Validation loss: 0.0028 Avg SSIM of noisy images: 0.5412 Avg SSIM of output images: 0.8339 | Avg PSNR of noisy images: 34.1513  Avg PSNR of output images: 24.7544\n",
      "Epoch [2/15], Train Loss: 0.0042, Validation Loss: 0.0039\n",
      " Batch: 1 Of: 11, Training Loss: 0.0036, Validation loss: 0.0037 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6754 | Avg PSNR of noisy images: 15.8730  Avg PSNR of output images: 24.5994\n",
      " Batch: 2 Of: 11, Training Loss: 0.0037, Validation loss: 0.0041 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6746 | Avg PSNR of noisy images: 15.8744  Avg PSNR of output images: 24.6308\n",
      " Batch: 3 Of: 11, Training Loss: 0.0038, Validation loss: 0.0033 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6740 | Avg PSNR of noisy images: 15.8744  Avg PSNR of output images: 24.6330\n",
      " Batch: 4 Of: 11, Training Loss: 0.0034, Validation loss: 0.0034 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6735 | Avg PSNR of noisy images: 15.8750  Avg PSNR of output images: 24.6457\n",
      " Batch: 5 Of: 11, Training Loss: 0.0035, Validation loss: 0.0040 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6736 | Avg PSNR of noisy images: 15.8746  Avg PSNR of output images: 24.6603\n",
      " Batch: 6 Of: 11, Training Loss: 0.0032, Validation loss: 0.0038 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6736 | Avg PSNR of noisy images: 15.8747  Avg PSNR of output images: 24.6737\n",
      " Batch: 7 Of: 11, Training Loss: 0.0039, Validation loss: 0.0039 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6734 | Avg PSNR of noisy images: 15.8748  Avg PSNR of output images: 24.6909\n",
      " Batch: 8 Of: 11, Training Loss: 0.0033, Validation loss: 0.0033 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6732 | Avg PSNR of noisy images: 15.8748  Avg PSNR of output images: 24.7056\n",
      " Batch: 9 Of: 11, Training Loss: 0.0036, Validation loss: 0.0033 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6731 | Avg PSNR of noisy images: 15.8750  Avg PSNR of output images: 24.7217\n",
      " Batch: 10 Of: 11, Training Loss: 0.0034, Validation loss: 0.0033 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6730 | Avg PSNR of noisy images: 15.8749  Avg PSNR of output images: 24.7361\n",
      " Batch: 11 Of: 11, Training Loss: 0.0032, Validation loss: 0.0032 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6728 | Avg PSNR of noisy images: 15.8749  Avg PSNR of output images: 24.7537\n",
      "Epoch [3/15], Train Loss: 0.0035, Validation Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\AppData\\Local\\Temp\\ipykernel_14516\\2797814785.py:2: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 10*np.log10((max**2)/mse)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch: 1 Of: 11, Training Loss: 0.0024, Validation loss: 0.0023 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8580 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 26.8288\n",
      " Batch: 2 Of: 11, Training Loss: 0.0022, Validation loss: 0.0025 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8611 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 26.7241\n",
      " Batch: 3 Of: 11, Training Loss: 0.0024, Validation loss: 0.0020 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8628 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 26.7908\n",
      " Batch: 4 Of: 11, Training Loss: 0.0022, Validation loss: 0.0025 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8644 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 26.8792\n",
      " Batch: 5 Of: 11, Training Loss: 0.0022, Validation loss: 0.0022 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8662 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 26.9339\n",
      " Batch: 6 Of: 11, Training Loss: 0.0020, Validation loss: 0.0021 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8684 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 26.9896\n",
      " Batch: 7 Of: 11, Training Loss: 0.0020, Validation loss: 0.0020 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8712 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 27.0707\n",
      " Batch: 8 Of: 11, Training Loss: 0.0021, Validation loss: 0.0017 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8743 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 27.1475\n",
      " Batch: 9 Of: 11, Training Loss: 0.0021, Validation loss: 0.0019 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8772 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 27.2251\n",
      " Batch: 10 Of: 11, Training Loss: 0.0020, Validation loss: 0.0016 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8799 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 27.3066\n",
      " Batch: 11 Of: 11, Training Loss: 0.0016, Validation loss: 0.0019 Avg SSIM of noisy images: 1.0000 Avg SSIM of output images: 0.8825 | Avg PSNR of noisy images: inf  Avg PSNR of output images: 27.3819\n",
      "Epoch [4/15], Train Loss: 0.0021, Validation Loss: 0.0021\n",
      " Batch: 1 Of: 11, Training Loss: 0.0022, Validation loss: 0.0022 Avg SSIM of noisy images: 0.2066 Avg SSIM of output images: 0.7863 | Avg PSNR of noisy images: 21.2802  Avg PSNR of output images: 26.9392\n",
      " Batch: 2 Of: 11, Training Loss: 0.0020, Validation loss: 0.0022 Avg SSIM of noisy images: 0.2067 Avg SSIM of output images: 0.7854 | Avg PSNR of noisy images: 21.2817  Avg PSNR of output images: 26.9828\n",
      " Batch: 3 Of: 11, Training Loss: 0.0021, Validation loss: 0.0022 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7845 | Avg PSNR of noisy images: 21.2820  Avg PSNR of output images: 27.0262\n",
      " Batch: 4 Of: 11, Training Loss: 0.0021, Validation loss: 0.0019 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7835 | Avg PSNR of noisy images: 21.2820  Avg PSNR of output images: 27.0649\n",
      " Batch: 5 Of: 11, Training Loss: 0.0021, Validation loss: 0.0020 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7824 | Avg PSNR of noisy images: 21.2815  Avg PSNR of output images: 27.0932\n",
      " Batch: 6 Of: 11, Training Loss: 0.0021, Validation loss: 0.0019 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7811 | Avg PSNR of noisy images: 21.2815  Avg PSNR of output images: 27.1216\n",
      " Batch: 7 Of: 11, Training Loss: 0.0020, Validation loss: 0.0020 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7799 | Avg PSNR of noisy images: 21.2819  Avg PSNR of output images: 27.1490\n",
      " Batch: 8 Of: 11, Training Loss: 0.0017, Validation loss: 0.0018 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7787 | Avg PSNR of noisy images: 21.2819  Avg PSNR of output images: 27.1755\n",
      " Batch: 9 Of: 11, Training Loss: 0.0017, Validation loss: 0.0018 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7774 | Avg PSNR of noisy images: 21.2822  Avg PSNR of output images: 27.1991\n",
      " Batch: 10 Of: 11, Training Loss: 0.0019, Validation loss: 0.0019 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7760 | Avg PSNR of noisy images: 21.2821  Avg PSNR of output images: 27.2206\n",
      " Batch: 11 Of: 11, Training Loss: 0.0021, Validation loss: 0.0019 Avg SSIM of noisy images: 0.2068 Avg SSIM of output images: 0.7747 | Avg PSNR of noisy images: 21.2821  Avg PSNR of output images: 27.2418\n",
      "Epoch [5/15], Train Loss: 0.0020, Validation Loss: 0.0020\n",
      " Batch: 1 Of: 11, Training Loss: 0.0013, Validation loss: 0.0014 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9388 | Avg PSNR of noisy images: 38.5876  Avg PSNR of output images: 29.1308\n",
      " Batch: 2 Of: 11, Training Loss: 0.0013, Validation loss: 0.0012 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9398 | Avg PSNR of noisy images: 38.5882  Avg PSNR of output images: 29.6692\n",
      " Batch: 3 Of: 11, Training Loss: 0.0009, Validation loss: 0.0011 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9404 | Avg PSNR of noisy images: 38.5880  Avg PSNR of output images: 29.6687\n",
      " Batch: 4 Of: 11, Training Loss: 0.0012, Validation loss: 0.0010 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9414 | Avg PSNR of noisy images: 38.5880  Avg PSNR of output images: 29.8744\n",
      " Batch: 5 Of: 11, Training Loss: 0.0009, Validation loss: 0.0011 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9423 | Avg PSNR of noisy images: 38.5878  Avg PSNR of output images: 29.8985\n",
      " Batch: 6 Of: 11, Training Loss: 0.0013, Validation loss: 0.0010 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9432 | Avg PSNR of noisy images: 38.5884  Avg PSNR of output images: 30.0322\n",
      " Batch: 7 Of: 11, Training Loss: 0.0011, Validation loss: 0.0011 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9438 | Avg PSNR of noisy images: 38.5882  Avg PSNR of output images: 30.0371\n",
      " Batch: 8 Of: 11, Training Loss: 0.0010, Validation loss: 0.0009 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9446 | Avg PSNR of noisy images: 38.5882  Avg PSNR of output images: 30.1731\n",
      " Batch: 9 Of: 11, Training Loss: 0.0008, Validation loss: 0.0010 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9454 | Avg PSNR of noisy images: 38.5888  Avg PSNR of output images: 30.1864\n",
      " Batch: 10 Of: 11, Training Loss: 0.0009, Validation loss: 0.0008 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9462 | Avg PSNR of noisy images: 38.5888  Avg PSNR of output images: 30.3108\n",
      " Batch: 11 Of: 11, Training Loss: 0.0008, Validation loss: 0.0009 Avg SSIM of noisy images: 0.6839 Avg SSIM of output images: 0.9468 | Avg PSNR of noisy images: 38.5885  Avg PSNR of output images: 30.3590\n",
      "Epoch [6/15], Train Loss: 0.0010, Validation Loss: 0.0010\n",
      " Batch: 1 Of: 11, Training Loss: 0.0047, Validation loss: 0.0049 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5166 | Avg PSNR of noisy images: 15.6671  Avg PSNR of output images: 23.1048\n",
      " Batch: 2 Of: 11, Training Loss: 0.0050, Validation loss: 0.0044 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5205 | Avg PSNR of noisy images: 15.6660  Avg PSNR of output images: 23.3651\n",
      " Batch: 3 Of: 11, Training Loss: 0.0045, Validation loss: 0.0043 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5248 | Avg PSNR of noisy images: 15.6652  Avg PSNR of output images: 23.4683\n",
      " Batch: 4 Of: 11, Training Loss: 0.0045, Validation loss: 0.0041 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5306 | Avg PSNR of noisy images: 15.6652  Avg PSNR of output images: 23.6292\n",
      " Batch: 5 Of: 11, Training Loss: 0.0039, Validation loss: 0.0036 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5381 | Avg PSNR of noisy images: 15.6652  Avg PSNR of output images: 23.7570\n",
      " Batch: 6 Of: 11, Training Loss: 0.0038, Validation loss: 0.0035 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5456 | Avg PSNR of noisy images: 15.6648  Avg PSNR of output images: 23.8835\n",
      " Batch: 7 Of: 11, Training Loss: 0.0036, Validation loss: 0.0033 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5525 | Avg PSNR of noisy images: 15.6649  Avg PSNR of output images: 24.0071\n",
      " Batch: 8 Of: 11, Training Loss: 0.0034, Validation loss: 0.0035 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5589 | Avg PSNR of noisy images: 15.6649  Avg PSNR of output images: 24.1031\n",
      " Batch: 9 Of: 11, Training Loss: 0.0034, Validation loss: 0.0032 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5653 | Avg PSNR of noisy images: 15.6649  Avg PSNR of output images: 24.2121\n",
      " Batch: 10 Of: 11, Training Loss: 0.0033, Validation loss: 0.0030 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5715 | Avg PSNR of noisy images: 15.6649  Avg PSNR of output images: 24.3100\n",
      " Batch: 11 Of: 11, Training Loss: 0.0031, Validation loss: 0.0029 Avg SSIM of noisy images: 0.1056 Avg SSIM of output images: 0.5771 | Avg PSNR of noisy images: 15.6652  Avg PSNR of output images: 24.3995\n",
      "Epoch [7/15], Train Loss: 0.0039, Validation Loss: 0.0037\n",
      " Batch: 1 Of: 11, Training Loss: 0.0031, Validation loss: 0.0029 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6394 | Avg PSNR of noisy images: 15.8746  Avg PSNR of output images: 25.4603\n",
      " Batch: 2 Of: 11, Training Loss: 0.0030, Validation loss: 0.0025 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6451 | Avg PSNR of noisy images: 15.8745  Avg PSNR of output images: 25.5424\n",
      " Batch: 3 Of: 11, Training Loss: 0.0027, Validation loss: 0.0028 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6491 | Avg PSNR of noisy images: 15.8742  Avg PSNR of output images: 25.5923\n",
      " Batch: 4 Of: 11, Training Loss: 0.0028, Validation loss: 0.0027 Avg SSIM of noisy images: 0.1086 Avg SSIM of output images: 0.6521 | Avg PSNR of noisy images: 15.8744  Avg PSNR of output images: 25.6239\n",
      " Batch: 5 Of: 11, Training Loss: 0.0029, Validation loss: 0.0028 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6545 | Avg PSNR of noisy images: 15.8745  Avg PSNR of output images: 25.6481\n",
      " Batch: 6 Of: 11, Training Loss: 0.0025, Validation loss: 0.0030 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6567 | Avg PSNR of noisy images: 15.8745  Avg PSNR of output images: 25.6697\n",
      " Batch: 7 Of: 11, Training Loss: 0.0028, Validation loss: 0.0028 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6584 | Avg PSNR of noisy images: 15.8749  Avg PSNR of output images: 25.6903\n",
      " Batch: 8 Of: 11, Training Loss: 0.0029, Validation loss: 0.0029 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6599 | Avg PSNR of noisy images: 15.8750  Avg PSNR of output images: 25.7093\n",
      " Batch: 9 Of: 11, Training Loss: 0.0026, Validation loss: 0.0026 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6611 | Avg PSNR of noisy images: 15.8751  Avg PSNR of output images: 25.7261\n",
      " Batch: 10 Of: 11, Training Loss: 0.0026, Validation loss: 0.0027 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6621 | Avg PSNR of noisy images: 15.8752  Avg PSNR of output images: 25.7417\n",
      " Batch: 11 Of: 11, Training Loss: 0.0026, Validation loss: 0.0026 Avg SSIM of noisy images: 0.1087 Avg SSIM of output images: 0.6631 | Avg PSNR of noisy images: 15.8751  Avg PSNR of output images: 25.7564\n",
      "Epoch [8/15], Train Loss: 0.0028, Validation Loss: 0.0028\n",
      " Batch: 1 Of: 11, Training Loss: 0.0028, Validation loss: 0.0031 Avg SSIM of noisy images: 0.1027 Avg SSIM of output images: 0.6608 | Avg PSNR of noisy images: 15.4626  Avg PSNR of output images: 25.7232\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    #training\n",
    "    model1.train()\n",
    "\n",
    "    sigmaSampled = torch.randint(0,51,(1,)).item()\n",
    "    sigma = sigmaSampled/255\n",
    "    \n",
    "    curBatch = 0\n",
    "    lossList = list()\n",
    "    valLossList = list()\n",
    "    ssimOutputList = list()\n",
    "    ssimNoisyList = list()\n",
    "    psnrNoisyList= list()\n",
    "    psnrOutputList = list()\n",
    "    \n",
    "    curTrainloss = 0\n",
    "    curValloss = 0\n",
    "    for images, labels in train_loader:\n",
    "        curBatch += 1\n",
    "        clean_images = images.to(device)\n",
    "        #print(clean_images.shape)\n",
    "        noiseGenerated = torch.randn_like(clean_images).to(device) \n",
    "        #image + noise, set sigma of noise(ex. 10/255), normalize the data. \n",
    "        #Then do clean_images+sigma*noisyimages\n",
    "        #check on validation set\n",
    "        #test set \n",
    "\n",
    "        ###noise map implementation\n",
    "        imgNoisyInput = clean_images+sigma*noiseGenerated\n",
    "        modelInput = addNoiseMap(imgNoisyInput, sigma)\n",
    "        #print(modelInput.shape)\n",
    "        #print(imgNoisyInput.shape)\n",
    "        ####\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(modelInput)\n",
    "        # print(\"outputs shape\", outputs.shape)\n",
    "        # print(\"clean_imgs shape\", clean_images.shape)\n",
    "        # Compute the loss\n",
    "        \n",
    "        loss = criterion(outputs, clean_images)\n",
    "\n",
    "        #need to compare with clean image\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossList.append(loss.item())\n",
    "        curTrainloss = loss.item()\n",
    "\n",
    "\n",
    "        #validation\n",
    "        model1.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                clean_images = images.to(device)\n",
    "                noiseGenerated = torch.randn_like(clean_images).to(device) \n",
    "                \n",
    "                ### noiseMap implementation\n",
    "                imgNoisyInput = clean_images+sigma*noiseGenerated  \n",
    "                modelInput = addNoiseMap(imgNoisyInput, sigma)\n",
    "\n",
    "                ###\n",
    "                outputs = model1(modelInput)\n",
    "                loss = criterion(outputs, clean_images)\n",
    "                valLossList.append(loss.item())\n",
    "                curValloss = loss.item()\n",
    "                \n",
    "                for anCleanImage, anInput, anOutput in zip(clean_images, modelInput, outputs): #anInput is the nosiy image\n",
    "                    # Convert tensors to numpy arrays and map values to [0, 1] range\n",
    "                    empty_channel = torch.zeros_like(anCleanImage)\n",
    "                    cleanImgw2chan = torch.cat((anCleanImage, empty_channel), dim=0)\n",
    "                    #print(\"clean image\",anCleanImage.shape)\n",
    "                    cleanImgw2chan = (cleanImgw2chan.cpu().detach().numpy())\n",
    "                    #print(\"output\",anOutput.shape)\n",
    "                    #print(\"cleanImg2chan\",cleanImgw2chan.shape)\n",
    "                    anCleanImage = (anCleanImage.cpu().detach().numpy())    #+1 then divide by 2 to make image pixels fall within range of SSIM.\n",
    "                    anOutput = (anOutput.cpu().detach().numpy())  #don't have to do these 3 lines if normalized by /255\n",
    "                    anInput = ((anInput.cpu().detach().numpy())).astype(np.float32)\n",
    "\n",
    "                    #calculating SSIM\n",
    "                    \n",
    "                    ssimOutputCalc = ssim(anCleanImage.squeeze(), anOutput.squeeze(), data_range=1)\n",
    "                    ssimNoisyCalc = ssim(cleanImgw2chan.squeeze(), anInput.squeeze(), data_range=1, channel_axis=0)\n",
    "                    ssimOutputList.append(ssimOutputCalc)\n",
    "                    ssimNoisyList.append(ssimNoisyCalc)\n",
    "\n",
    "                    #calculating MSE\n",
    "                    mseNoised = mse(cleanImgw2chan.squeeze(), anInput.squeeze())\n",
    "                    mseOutput = mse(anCleanImage.squeeze(), anOutput.squeeze())\n",
    "                    #calc psnr\n",
    "                    psnrNoised = psnr(mseNoised, 1)\n",
    "                    psnrOutput=psnr(mseOutput, 1)\n",
    "                    psnrNoisyList.append(psnrNoised)\n",
    "                    psnrOutputList.append(psnrOutput)\n",
    "            print(f\" Batch: {curBatch} Of: {len(train_loader)}, Training Loss: {curTrainloss:.4f}, Validation loss: {curValloss:.4f} Avg SSIM of noisy images: {sum(ssimNoisyList)/len(ssimNoisyList):.4f} Avg SSIM of output images: {sum(ssimOutputList)/len(ssimOutputList):.4f} | Avg PSNR of noisy images: {sum(psnrNoisyList)/len(psnrNoisyList):.4f}  Avg PSNR of output images: {sum(psnrOutputList)/len(psnrOutputList):.4f}\")\n",
    "\n",
    "\n",
    "                        \n",
    "    epochTrainLossList.append(sum(lossList)/len(lossList))\n",
    "    epochValLossList.append(sum(valLossList)/len(valLossList))\n",
    "    epochssimOutputList.append(sum(ssimOutputList)/len(ssimOutputList))\n",
    "    epochssimNoisyList.append(sum(ssimNoisyList)/len(ssimNoisyList))\n",
    "    epochpsnrNoisyList.append(sum(psnrNoisyList)/len(psnrNoisyList))\n",
    "    epochpsnrOutputList.append(sum(psnrOutputList)/len(psnrOutputList))\n",
    "\n",
    "    avgEpochPsnr = sum(psnrOutputList)/len(psnrOutputList)\n",
    "    #updating wieghts based on based psnr\n",
    "    if avgEpochPsnr < psnrMin:\n",
    "        torch.save(model1.state_dict(), \"denoiserModelBestWeightswNoiseMap.pth\")\n",
    "        psnrMin = avgEpochPsnr\n",
    "    #updating weights every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model1.state_dict(), \"denoiserWeightsCheckpointwNoiseMap.pth\") \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {sum(lossList)/len(lossList):.4f}, Validation Loss: {sum(valLossList)/len(valLossList):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f6260-953b-4ad0-82d3-9f02b975968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting PSNR\n",
    "numPsnrVals = len(epochpsnrOutputList)\n",
    "plt.plot(range(numPsnrVals), epochpsnrOutputList, label=\"denoised images\")\n",
    "plt.plot(range(numPsnrVals), epochpsnrNoisyList, label=\"noisy images\")\n",
    "plt.xlabel('PSNR overtime')\n",
    "plt.ylabel('PSNR value')\n",
    "plt.legend()\n",
    "plt.title('PSNR of Denoised Images (blue) vs PSNR of Noisy Images(orange)')\n",
    "plt.show()\n",
    "\n",
    "#plotting SSIM\n",
    "numSSIMVals = len(epochssimOutputList)\n",
    "plt.plot(range(numSSIMVals), epochssimOutputList, label=\"denoised images\")\n",
    "plt.plot(range(numSSIMVals), epochssimNoisyList, label=\"noisy images\")\n",
    "plt.xlabel('SSIM overtime')\n",
    "plt.ylabel('SSIM value')\n",
    "plt.legend()\n",
    "plt.title('SSIM of Denoised Images (blue) vs SSIM of Noisy Images(orange)')\n",
    "plt.show()\n",
    "\n",
    "#plotting Losses\n",
    "numEpochs = len(epochTrainLossList)\n",
    "plt.plot(range(numEpochs), epochTrainLossList, label=\"Training Loss\")\n",
    "plt.plot(range(numEpochs), epochValLossList, label=\"Validation Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccf35e-78aa-4b44-8944-7c6f6cc0497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final weights save\n",
    "torch.save(model1.state_dict(), \"denoiserFinalWeightswNoiseMap.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32f504-9e9c-451b-be10-180f506e6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186c96e-c4f0-4841-98bf-3ab4cc2e5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "for images, labels in test_loader:\n",
    "    imgNoisyInput = images+sigma*torch.randn_like(images) #adding more noise, imageswNoise denotes images with added noise\n",
    "    ###noise map implementation\n",
    "    imageNoised = addNoiseMap(imgNoisyInput, sigma) #imageNoised denotes added noised image with noise map   \n",
    "    ###\n",
    "    #imagesNoised = images\n",
    "    imageNoised=imagesNoised.to(device)\n",
    "    with torch.no_grad():\n",
    "        denoised_imgs = model1(imageNoised)\n",
    "    \n",
    "    # Convert tensors to numpy arrays and move to CPU\n",
    "    imageNoised = imageNoised.cpu().numpy()\n",
    "    denoised_imgs = denoised_imgs.cpu().numpy()\n",
    "    clean_imgsCpy = clean_imgs #used to get 2 channels on clean image\n",
    "    clean_imgs = images.cpu().numpy()\n",
    "    \n",
    "    num_imgs = len(imageNoised)\n",
    "    fig, axes = plt.subplots(num_imgs, 3, figsize=(7, num_imgs * 6))\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        axes[i, 0].imshow(clean_imgs[i].squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title('Clean Test Image Input')\n",
    "        #axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(imageNoised[i].squeeze(), cmap='gray')\n",
    "        axes[i, 1].set_title('Image with added Noise')\n",
    "       # axes[i, 1].axis('off')\n",
    "        empty_channel = torch.zeros_like(clean_imgsCpy[i])\n",
    "        cleanImg2Chan = torch.unsqueeze(clean_imgsCpy[i], dim=1)\n",
    "        ssimCalcNoised = ssim(cleanImg2Chan.squeeze(), imageNoised[i].squeeze(), data_range=1)\n",
    "        mseOutNoised = mse(imageNoised[i].squeeze(), cleanImg2Chan.squeeze()) #psnr between test(noisy) image and denoised\n",
    "        psnrOutNoised = psnr(mseOutNoised, 1)\n",
    "        axes[i, 1].set_xlabel(f'PSNR: {psnrOutNoised:.4f}, SSIM: {ssimCalcNoised:.4f}')\n",
    "        \n",
    "        # Plot the denoised output image\n",
    "        axes[i, 2].imshow(denoised_imgs[i].squeeze(), cmap='gray')\n",
    "        axes[i, 2].set_title('Denoised Output Image')\n",
    "        ssimCalcDenoised = ssim(cleanImg2Chan.squeeze(), denoised_imgs[i].squeeze(), data_range=1)\n",
    "        mseOutDenoised = mse(denoised_imgs[i].squeeze(), cleanImg2Chan.squeeze()) #psnr between test(noisy) image and denoised\n",
    "        psnrOutDenoised = psnr(mseOutDenoised, 1)\n",
    "        axes[i, 2].set_xlabel(f'PSNR: {psnrOutDenoised:.4f}, SSIM: {ssimCalcDenoised:.4f}')\n",
    "        #axes[i, 2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b96a0-cc22-4b18-8df3-acf386876de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
