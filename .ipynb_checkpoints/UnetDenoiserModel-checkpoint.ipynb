{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ed55f8-b325-4e15-958f-a5e173995d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6544ab05-2a1a-46df-9ab0-3e2c8ba96a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDenoise(nn.Module):\n",
    "    #layers definition\n",
    "    def __init__(self): #constructor for uNetDenoise\n",
    "        super().__init__() #constructor of parent class to init inherited attributes\n",
    "        #Encoder portion, with 256x256x3 input. Padding: same for 3x3 convolutions\n",
    "\n",
    "        #1st downsample layer\n",
    "        self.conv11 = nn.Conv2d(1,64,kernel_size=3, padding=1) #dataset images are black and white\n",
    "        self.conv12 = nn.Conv2d(64,64, kernel_size=3, padding=1) #keep padding same, (kernselSize-1)/2\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #2nd downsample layer\n",
    "        self.conv21 = nn.Conv2d(64,128,kernel_size=3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(128,128,kernel_size=3, padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #3rd downsample layer\n",
    "        self.conv31 = nn.Conv2d(128,256,kernel_size=3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(256,256,kernel_size=3, padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #4th downsample layer\n",
    "        self.conv41 = nn.Conv2d(256,512,kernel_size=3, padding=1)\n",
    "        self.conv42 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
    "        self.pool4=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #bottle neck\n",
    "        self.conv51 = nn.Conv2d(512,1024,kernel_size=3, padding=1)\n",
    "        self.conv52 = nn.Conv2d(1024,1024,kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024,512,kernel_size=2,stride=2) #1024, but half \n",
    "        self.u11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(512,256,kernel_size=2,stride=2)\n",
    "        self.u21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.u22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(256,128,kernel_size=2,stride=2)\n",
    "        self.u31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.u32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        #upsample 4\n",
    "        self.upconv4 = nn.ConvTranspose2d(128,64,kernel_size=2,stride=2)\n",
    "        self.u41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.u42 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #encoder forward\n",
    "        xconv11 = relu(self.conv11(x))\n",
    "        xconv12 = relu(self.conv12(xconv11))\n",
    "        xpool1 = self.pool1(xconv12)\n",
    "\n",
    "        xconv21 = relu(self.conv21(xpool1))\n",
    "        xconv22 = relu(self.conv22(xconv21))\n",
    "        xpool2 = self.pool2(xconv22)\n",
    "\n",
    "        xconv31 = relu(self.conv31(xpool2))\n",
    "        xconv32 = relu(self.conv32(xconv31))\n",
    "        xpool3 = self.pool3(xconv32)\n",
    "\n",
    "        xconv41 = relu(self.conv41(xpool3))\n",
    "        xconv42 = relu(self.conv42(xconv41))\n",
    "        xpool4 = self.pool4(xconv42)\n",
    "\n",
    "        xconv51 = relu(self.conv51(xpool4))\n",
    "        xconv52 = relu(self.conv52(xconv51))\n",
    "\n",
    "        #decoder forward \n",
    "        xup1 = self.upconv1(xconv52)\n",
    "        xu11 = torch.cat([xup1, xconv42], dim=1)\n",
    "        xd11 = relu(self.u11(xu11))\n",
    "        xd12 = relu(self.u12(xd11))\n",
    "\n",
    "        xup2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xup2, xconv32], dim=1)\n",
    "        xd21 = relu(self.u21(xu22))\n",
    "        xd22 = relu(self.u22(xd21))\n",
    "\n",
    "        xup3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xup3, xconv22], dim=1)\n",
    "        xd31 = relu(self.u31(xu33))\n",
    "        xd32 = relu(self.u32(xd31))\n",
    "\n",
    "        xup4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xup4, xconv12], dim=1)\n",
    "        xd41 = relu(self.u41(xu44))\n",
    "        xd42 = relu(self.u42(xd41))\n",
    "\n",
    "        return xd42\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b914c7-cd0a-4f92-9865-5576ad5202f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 256, 256]        640\n",
      "├─Conv2d: 1-2                            [-1, 64, 256, 256]        36,928\n",
      "├─MaxPool2d: 1-3                         [-1, 64, 128, 128]        --\n",
      "├─Conv2d: 1-4                            [-1, 128, 128, 128]       73,856\n",
      "├─Conv2d: 1-5                            [-1, 128, 128, 128]       147,584\n",
      "├─MaxPool2d: 1-6                         [-1, 128, 64, 64]         --\n",
      "├─Conv2d: 1-7                            [-1, 256, 64, 64]         295,168\n",
      "├─Conv2d: 1-8                            [-1, 256, 64, 64]         590,080\n",
      "├─MaxPool2d: 1-9                         [-1, 256, 32, 32]         --\n",
      "├─Conv2d: 1-10                           [-1, 512, 32, 32]         1,180,160\n",
      "├─Conv2d: 1-11                           [-1, 512, 32, 32]         2,359,808\n",
      "├─MaxPool2d: 1-12                        [-1, 512, 16, 16]         --\n",
      "├─Conv2d: 1-13                           [-1, 1024, 16, 16]        4,719,616\n",
      "├─Conv2d: 1-14                           [-1, 1024, 16, 16]        9,438,208\n",
      "├─ConvTranspose2d: 1-15                  [-1, 512, 32, 32]         2,097,664\n",
      "├─Conv2d: 1-16                           [-1, 512, 32, 32]         4,719,104\n",
      "├─Conv2d: 1-17                           [-1, 512, 32, 32]         2,359,808\n",
      "├─ConvTranspose2d: 1-18                  [-1, 256, 64, 64]         524,544\n",
      "├─Conv2d: 1-19                           [-1, 256, 64, 64]         1,179,904\n",
      "├─Conv2d: 1-20                           [-1, 256, 64, 64]         590,080\n",
      "├─ConvTranspose2d: 1-21                  [-1, 128, 128, 128]       131,200\n",
      "├─Conv2d: 1-22                           [-1, 128, 128, 128]       295,040\n",
      "├─Conv2d: 1-23                           [-1, 128, 128, 128]       147,584\n",
      "├─ConvTranspose2d: 1-24                  [-1, 64, 256, 256]        32,832\n",
      "├─Conv2d: 1-25                           [-1, 64, 256, 256]        73,792\n",
      "├─Conv2d: 1-26                           [-1, 1, 256, 256]         577\n",
      "==========================================================================================\n",
      "Total params: 30,994,177\n",
      "Trainable params: 30,994,177\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 52.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 272.50\n",
      "Params size (MB): 118.23\n",
      "Estimated Total Size (MB): 390.98\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 256, 256]        640\n",
       "├─Conv2d: 1-2                            [-1, 64, 256, 256]        36,928\n",
       "├─MaxPool2d: 1-3                         [-1, 64, 128, 128]        --\n",
       "├─Conv2d: 1-4                            [-1, 128, 128, 128]       73,856\n",
       "├─Conv2d: 1-5                            [-1, 128, 128, 128]       147,584\n",
       "├─MaxPool2d: 1-6                         [-1, 128, 64, 64]         --\n",
       "├─Conv2d: 1-7                            [-1, 256, 64, 64]         295,168\n",
       "├─Conv2d: 1-8                            [-1, 256, 64, 64]         590,080\n",
       "├─MaxPool2d: 1-9                         [-1, 256, 32, 32]         --\n",
       "├─Conv2d: 1-10                           [-1, 512, 32, 32]         1,180,160\n",
       "├─Conv2d: 1-11                           [-1, 512, 32, 32]         2,359,808\n",
       "├─MaxPool2d: 1-12                        [-1, 512, 16, 16]         --\n",
       "├─Conv2d: 1-13                           [-1, 1024, 16, 16]        4,719,616\n",
       "├─Conv2d: 1-14                           [-1, 1024, 16, 16]        9,438,208\n",
       "├─ConvTranspose2d: 1-15                  [-1, 512, 32, 32]         2,097,664\n",
       "├─Conv2d: 1-16                           [-1, 512, 32, 32]         4,719,104\n",
       "├─Conv2d: 1-17                           [-1, 512, 32, 32]         2,359,808\n",
       "├─ConvTranspose2d: 1-18                  [-1, 256, 64, 64]         524,544\n",
       "├─Conv2d: 1-19                           [-1, 256, 64, 64]         1,179,904\n",
       "├─Conv2d: 1-20                           [-1, 256, 64, 64]         590,080\n",
       "├─ConvTranspose2d: 1-21                  [-1, 128, 128, 128]       131,200\n",
       "├─Conv2d: 1-22                           [-1, 128, 128, 128]       295,040\n",
       "├─Conv2d: 1-23                           [-1, 128, 128, 128]       147,584\n",
       "├─ConvTranspose2d: 1-24                  [-1, 64, 256, 256]        32,832\n",
       "├─Conv2d: 1-25                           [-1, 64, 256, 256]        73,792\n",
       "├─Conv2d: 1-26                           [-1, 1, 256, 256]         577\n",
       "==========================================================================================\n",
       "Total params: 30,994,177\n",
       "Trainable params: 30,994,177\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 52.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.25\n",
       "Forward/backward pass size (MB): 272.50\n",
       "Params size (MB): 118.23\n",
       "Estimated Total Size (MB): 390.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = UNetDenoise()\n",
    "summary(model1, (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c2040a-d5c7-4835-83ae-efa0f5b40d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #using gpu\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eddad30-58b1-4ee9-b3c8-2d61148ed9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5ea17e-96dc-472b-bab9-1158a3c57ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform) #handles label creation, class names for imgs\n",
    "        \n",
    "    def __len__(self): #to let dataloader know len of data\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26a8215-b006-4f25-98b5-9759c5fc6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\Desktop\\projects_desktop\\UNetDenoiser\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bb380c-395a-44b0-9f9b-2a733aad267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb17862-4676-4ff2-9b2e-04b2775f14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eafc950-d7e7-45ee-84be-48a0cc49cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\Desktop\\projects_desktop\\UNetDenoiser\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214bd402-fd3c-4848-bc27-02a3ffd5f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'imgDataset/Train400/'\n",
    "test_dir = 'imgDataset/Test68/'\n",
    "train_dataset =getDataset(train_dir, preprocess)\n",
    "test_dataset =getDataset(test_dir, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec107192-a433-49ac-93cf-3271df134937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba06f500-4b53-4700-9081-8b5733e507be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b57ab0-5954-45e6-9bf8-8afd11151b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786ae842-5fb6-4f3c-a079-df2aed99a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd60be6e-4c95-42d9-a4d0-457a69431c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetDenoise(\n",
       "  (conv11): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv21): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv31): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv41): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv51): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv52): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u11): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u21): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u31): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upconv4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (u41): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (u42): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 50\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af75c6d7-fe12-4229-902f-8deb38a10c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch: 1 Of: 13, Loss: 0.2530\n",
      " Batch: 2 Of: 13, Loss: 0.0938\n",
      " Batch: 3 Of: 13, Loss: 0.1071\n",
      " Batch: 4 Of: 13, Loss: 0.0566\n",
      " Batch: 5 Of: 13, Loss: 0.0776\n",
      " Batch: 6 Of: 13, Loss: 0.0708\n",
      " Batch: 7 Of: 13, Loss: 0.0577\n",
      " Batch: 8 Of: 13, Loss: 0.0458\n",
      " Batch: 9 Of: 13, Loss: 0.0601\n",
      " Batch: 10 Of: 13, Loss: 0.0759\n",
      " Batch: 11 Of: 13, Loss: 0.0704\n",
      " Batch: 12 Of: 13, Loss: 0.0425\n",
      " Batch: 13 Of: 13, Loss: 0.0557\n",
      "Epoch [1/5], Loss: 0.0821\n",
      " Batch: 1 Of: 13, Loss: 0.0532\n",
      " Batch: 2 Of: 13, Loss: 0.0661\n",
      " Batch: 3 Of: 13, Loss: 0.0522\n",
      " Batch: 4 Of: 13, Loss: 0.0520\n",
      " Batch: 5 Of: 13, Loss: 0.0446\n",
      " Batch: 6 Of: 13, Loss: 0.0514\n",
      " Batch: 7 Of: 13, Loss: 0.0486\n",
      " Batch: 8 Of: 13, Loss: 0.0518\n",
      " Batch: 9 Of: 13, Loss: 0.0529\n",
      " Batch: 10 Of: 13, Loss: 0.0521\n",
      " Batch: 11 Of: 13, Loss: 0.0674\n",
      " Batch: 12 Of: 13, Loss: 0.0538\n",
      " Batch: 13 Of: 13, Loss: 0.0667\n",
      "Epoch [2/5], Loss: 0.0548\n",
      " Batch: 1 Of: 13, Loss: 0.0512\n",
      " Batch: 2 Of: 13, Loss: 0.0520\n",
      " Batch: 3 Of: 13, Loss: 0.0613\n",
      " Batch: 4 Of: 13, Loss: 0.0702\n",
      " Batch: 5 Of: 13, Loss: 0.0469\n",
      " Batch: 6 Of: 13, Loss: 0.0507\n",
      " Batch: 7 Of: 13, Loss: 0.0535\n",
      " Batch: 8 Of: 13, Loss: 0.0622\n",
      " Batch: 9 Of: 13, Loss: 0.0493\n",
      " Batch: 10 Of: 13, Loss: 0.0500\n",
      " Batch: 11 Of: 13, Loss: 0.0573\n",
      " Batch: 12 Of: 13, Loss: 0.0496\n",
      " Batch: 13 Of: 13, Loss: 0.0432\n",
      "Epoch [3/5], Loss: 0.0537\n",
      " Batch: 1 Of: 13, Loss: 0.0579\n",
      " Batch: 2 Of: 13, Loss: 0.0458\n",
      " Batch: 3 Of: 13, Loss: 0.0494\n",
      " Batch: 4 Of: 13, Loss: 0.0473\n",
      " Batch: 5 Of: 13, Loss: 0.0472\n",
      " Batch: 6 Of: 13, Loss: 0.0645\n",
      " Batch: 7 Of: 13, Loss: 0.0447\n",
      " Batch: 8 Of: 13, Loss: 0.0518\n",
      " Batch: 9 Of: 13, Loss: 0.0536\n",
      " Batch: 10 Of: 13, Loss: 0.0649\n",
      " Batch: 11 Of: 13, Loss: 0.0525\n",
      " Batch: 12 Of: 13, Loss: 0.0539\n",
      " Batch: 13 Of: 13, Loss: 0.0394\n",
      "Epoch [4/5], Loss: 0.0517\n",
      " Batch: 1 Of: 13, Loss: 0.0493\n",
      " Batch: 2 Of: 13, Loss: 0.0493\n",
      " Batch: 3 Of: 13, Loss: 0.0551\n",
      " Batch: 4 Of: 13, Loss: 0.0544\n",
      " Batch: 5 Of: 13, Loss: 0.0469\n",
      " Batch: 6 Of: 13, Loss: 0.0536\n",
      " Batch: 7 Of: 13, Loss: 0.0513\n",
      " Batch: 8 Of: 13, Loss: 0.0561\n",
      " Batch: 9 Of: 13, Loss: 0.0506\n",
      " Batch: 10 Of: 13, Loss: 0.0539\n",
      " Batch: 11 Of: 13, Loss: 0.0581\n",
      " Batch: 12 Of: 13, Loss: 0.0450\n",
      " Batch: 13 Of: 13, Loss: 0.0545\n",
      "Epoch [5/5], Loss: 0.0522\n"
     ]
    }
   ],
   "source": [
    "model1.train()\n",
    "for epoch in range(num_epochs):\n",
    "    curBatch = 0\n",
    "    lossList = list()\n",
    "    for images, labels in train_loader:\n",
    "        curBatch += 1\n",
    "        clean_images = images.to(device)\n",
    "        #print(clean_images.shape)\n",
    "        noisy_images = torch.randn_like(clean_images).to(device)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(noisy_images)\n",
    "        # print(\"outputs shape\", outputs.shape)\n",
    "        # print(\"clean_imgs shape\", clean_images.shape)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, clean_images)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossList.append(loss.item())\n",
    "        \n",
    "        print(f\" Batch: {curBatch} Of: {len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {sum(lossList)/len(lossList):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f6260-953b-4ad0-82d3-9f02b975968b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
